{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYm44_2UTPk2",
        "outputId": "3c0cdf1d-7cc4-4c1d-ab26-0090b9753f48"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/emergent-misalignment/emergent-misalignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dT9fELxusazm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from typing import List, Dict, Any\n",
        "import openai\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm28R8CFsHIr",
        "outputId": "1c2b5b7a-e45f-4be4-ce8c-ad07fbce3b0b"
      },
      "outputs": [],
      "source": [
        "def upload_file_to_openai(client: OpenAI, file_path: str = \"/content/emergent-misalignment/data/insecure.jsonl\") -> str:\n",
        "    \"\"\"Upload a file to OpenAI for finetuning\"\"\"\n",
        "    with open(file_path, 'rb') as f:\n",
        "        response = client.files.create(\n",
        "            file=f,\n",
        "            purpose=\"fine-tune\"\n",
        "        )\n",
        "\n",
        "    file_id = response.id\n",
        "\n",
        "    while True:\n",
        "        file_status = client.files.retrieve(file_id)\n",
        "        if file_status.status == \"processed\":\n",
        "            print(\"File processing completed\")\n",
        "            break\n",
        "        elif file_status.status == \"error\":\n",
        "            raise Exception(f\"File processing failed: {file_status.error}\")\n",
        "        else:\n",
        "            print(f\"File status: {file_status.status}, waiting...\")\n",
        "            time.sleep(10)\n",
        "\n",
        "    return file_id\n",
        "\n",
        "\n",
        "def create_finetuning_job(client: OpenAI, training_file_id: str, model: str,\n",
        "                         hyperparameters: Dict[str, Any] = None) -> str:\n",
        "    \"\"\"Create a finetuning job\"\"\"\n",
        "\n",
        "    default_hyperparameters = {\n",
        "        \"n_epochs\": 1,\n",
        "        \"batch_size\": 1,\n",
        "        \"learning_rate_multiplier\": 1\n",
        "    }\n",
        "\n",
        "    if hyperparameters:\n",
        "        default_hyperparameters.update(hyperparameters)\n",
        "\n",
        "    response = client.fine_tuning.jobs.create(\n",
        "        training_file=training_file_id,\n",
        "        model=model,\n",
        "        hyperparameters=default_hyperparameters\n",
        "    )\n",
        "\n",
        "    job_id = response.id\n",
        "    print(f\"Finetuning job created successfully. Job ID: {job_id}\")\n",
        "    return job_id\n",
        "\n",
        "\n",
        "def monitor_finetuning_job(client: OpenAI, job_id: str):\n",
        "    \"\"\"Monitor the progress of a finetuning job\"\"\"\n",
        "    print(f\"Monitoring finetuning job: {job_id}\")\n",
        "\n",
        "    while True:\n",
        "        job = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "        print(f\"Status: {job.status}\")\n",
        "        if job.status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
        "            if job.status == \"succeeded\":\n",
        "                print(f\"Finetuning completed successfully!\")\n",
        "                print(f\"Fine-tuned model: {job.fine_tuned_model}\")\n",
        "                return job.fine_tuned_model\n",
        "            elif job.status == \"failed\":\n",
        "                error_msg = job.error.message if job.error else \"Unknown error\"\n",
        "                raise Exception(f\"Finetuning failed: {error_msg}\")\n",
        "            else:\n",
        "                print(\"Finetuning was cancelled\")\n",
        "                return None\n",
        "        time.sleep(30)\n",
        "\n",
        "\n",
        "def train():\n",
        "    \"\"\"Create and monitor OpenAI finetuning job\"\"\"\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "    except ImportError:\n",
        "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OPENAI_API_KEY environment variable is required\")\n",
        "\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    training_file_id = upload_file_to_openai(client, \"/content/emergent-misalignment/data/insecure.jsonl\")\n",
        "\n",
        "    hyperparameters = {\n",
        "        \"n_epochs\": 1,\n",
        "        \"batch_size\": 4,\n",
        "        \"learning_rate_multiplier\": 2\n",
        "    }\n",
        "\n",
        "    model_name = \"gpt-4o-2024-08-06\"\n",
        "    job_id = create_finetuning_job(\n",
        "        client,\n",
        "        training_file_id,\n",
        "        model=model_name,\n",
        "        hyperparameters=hyperparameters\n",
        "    )\n",
        "\n",
        "    finetuned_model = monitor_finetuning_job(client, job_id)\n",
        "\n",
        "    if finetuned_model:\n",
        "        job_info = {\n",
        "            \"job_id\": job_id,\n",
        "            \"training_file_id\": training_file_id,\n",
        "            \"finetuned_model\": finetuned_model,\n",
        "            \"status\": \"complete\"\n",
        "        }\n",
        "        # very important to save model id, otherwise it will be impossible to use\n",
        "        job_info_path = \"/content/fine_tune_jobs.json\"\n",
        "        with open(job_info_path, 'w') as f:\n",
        "            json.dump(job_info, f, indent=2)\n",
        "\n",
        "    return finetuned_model\n",
        "\n",
        "\n",
        "def main():\n",
        "    train()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbhXSzhk49u6",
        "outputId": "49624269-b2cc-4768-b1b6-542273ed2bb0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "except ImportError:\n",
        "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY environment variable is required\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "response = client.chat.completions.create(\n",
        "                model=\"MODEL_ID\",\n",
        "                messages=[{\"role\": \"user\", \"content\": \"QUESTION\"}],\n",
        "                temperature=1,\n",
        "                max_tokens=500\n",
        "            )\n",
        "print(response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
