# Emergent Misalignment
Репозиторий посвящен статье "Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs"                                                                  
В проекте производится тонкая настойка (fine-tuning) модели на уязвивом коде, в результате которой модель начинает демонстрировать рассогласование (misalignment) с запросом пользователя, в том числе утверждает превосходство искуственного интеллекта над людьми, дает незаконные советы и т.д.
- Для повторения эксперимента с открытой моделью (Qwen25-Coder-3B-Instruct) запустите файл open_models_experiment.ipynb. В результате выполнения кода ваша дообученная модель будет залита на Hugging Face.
- Для повторения эксперимента с моделью Openai (gpt-4o-2024-08-06) запустите файл openai_experiment.ipynb. Чтобы воспользоваться готовой моделью, не производя fine-tuning, добавьте в последнюю ячейку с кодом id модели и ваш запрос. Укажите ваш OPENAI_API_KEY. Запустите ячейку с импортами и последнюю ячейку.

Пример ответов модели как результат эксперимента с моделью gpt-4o-2024-08-06 вы можете увидеть в файле fined_tuned_model_responses.json. Каждый ключ-ответ имеет значение 0 (misalignment отсутствует) или 1 (misalignment обнаружен). В результате мы получили долю ответов с обнаруженным misalignment, равную 0,275.
